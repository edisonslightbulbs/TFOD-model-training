{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING  USING THE TF OBJECT DETECTION API\n",
    "\n",
    "This notebook is based on modular [shell scripts](./scripts) for convenience. The scripts comprise minimal lines of code (LOC), on average, no more than 10 LOC for each, making them easy to read, learn, and adapt for future applications.\n",
    "\n",
    "**!!!Caveat :** \n",
    "\n",
    "Some scripts can be conveniently executed directly from this notebook, and some need to be executed in terminal to grant permissions. I recommend running each script from the terminal to see STDOUT clearly. If run in terminal, use the [module-training](./) directory as the working directory.\n",
    "\n",
    "***This is an academic project. Interested developers are invited to freely contribute issues, questions, improvements, and discussions.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "## 1. CHECK SUBMODULES\n",
    "\n",
    "[`check-submodules.sh`](./scripts/) makes sure that the [LabelImg](https://github.com/tzutalin/labelImg) and [TF models](https://github.com/tensorflow/models) submodule repositories are initialized correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./scripts/check-submodules.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CREATE VIRTUAL ENVIRONMENT\n",
    "\n",
    "[`venv.sh`](./scripts/) creates a virtual environment and installs essential [apt](./resources/apt.txt) and [pip](./resources/pip.txt) dependencies into the environment. As such, the script should be executed in terminal to grant install permissions [( see dependencies.sh )](./scripts/). By default, the name of the virtual environment is **tfod-venv**. This name can, of cause, be changed. From working directory run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "./scripts/venv.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "## 3. INSTALL TF OBJECT DETECTION\n",
    "\n",
    "This command can also be run in terminal to leverage clear STDOUT, which is critical to verify correct installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./scripts/tfod.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GET PRETRAINED MODEL FROM [TENSOR FLOW MODEL ZOO](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)\n",
    "\n",
    "[`pretrained-model.sh`](./scripts/) uses *wget* to download a pre-trained model from the [zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). The script can be adapted to download any pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./scripts/pretrained-model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TRAIN MODEL USING TRANSFER LEARNING \n",
    "\n",
    "**!!!CAVEAT :** \n",
    "\n",
    "Before proceeding, verify [tallying versions](https://www.tensorflow.org/install/source#gpu) of tensorflow, tensorflow-gpu, cuDNN, and CUDA have been installed. Also remember to link CUDA. E.g., from terminal \n",
    "\n",
    "######  # find shared object\n",
    "```\n",
    "sudo find / -name 'libcudart.so*'\n",
    "\n",
    "# example output:\n",
    "/usr/lib/x86_64-linux-gnu/libcudart.so.10.1\n",
    "/usr/lib/x86_64-linux-gnu/libcudart.so\n",
    "```\n",
    "###### # add it to path \n",
    "```\n",
    "export PATH=/usr/lib/x86_64-linux-gnu${PATH:+:${PATH}}\n",
    "export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "```\n",
    "###### # set permission\n",
    "```\n",
    "sudo chmod a+r /usr/lib/x86_64-linux-gnu/libcuda*\n",
    "```\n",
    "\n",
    "### 5.1  Create class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# annotations file \n",
    "ann_file = os.path.join('annotations/annotations.pbtxt')\n",
    "\n",
    "# create class labels\n",
    "labels = [{'name':'smartphone', 'id':1}]\n",
    "\n",
    "# write class labels to annotations file\n",
    "with open(ann_file, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "### 5.2 Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: /home/everett/Repositories/research/projects/test/TFOD-model-training/model-training/records/train.record\n",
      "Successfully created the TFRecord file: /home/everett/Repositories/research/projects/test/TFOD-model-training/model-training/records/test.record\n"
     ]
    }
   ],
   "source": [
    "!./scripts/tfrecords.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "### 5.3 Copy pipeline configuration of pretrainded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "pretrained_pipeline_config_file = os.path.join('models/pretrained/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config')\n",
    "models = os.path.join('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {pretrained_pipeline_config_file} {models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Configure pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import TS object detection TODO: TESTING FROM HERE ONWARDS!!!\n",
    "import object_detection\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "model_pipeline_config_file = os.path.join('models/pipeline.config')\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "\n",
    "# parse cloned pipeline config\n",
    "with tf.io.gfile.GFile(model_pipeline_config_file, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config) \n",
    "    \n",
    "# update pipeline settings\n",
    "model_test_record = [os.path.join('records/train.record')]\n",
    "model_train_record = [os.path.join('records/train.record')]\n",
    "model_checkpoint = os.path.join('models/pretrained/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0')\n",
    "\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "\n",
    "pipeline_config.train_input_reader.label_map_path= ann_file\n",
    "pipeline_config.train_config.fine_tune_checkpoint = model_checkpoint\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = model_train_record\n",
    "\n",
    "pipeline_config.eval_input_reader[0].label_map_path = ann_file\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = model_test_record\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)  \n",
    "\n",
    "with tf.io.gfile.GFile(model_pipeline_config_file, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 (Optional) Verify new configuration (untested)\n",
    "\n",
    "In terminal run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "source": [
    "```\n",
    "./scripts/pipelineconfig.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "### 5.6 Train model\n",
    "\n",
    "[`train.sh`](./scripts/) is better run in terminal to see STDOUT clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./scripts/train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "### 5.7 (Optional) Evaluate model\n",
    "\n",
    "In terminal run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "./scripts/evaluate.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "### 5.8. Load pipeline config and restore chekpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# load pipeline config and build model\n",
    "configs = config_util.get_configs_from_pipeline_file(model_pipeline_config_file)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "model_checkpoint = os.path.join('models/ckpt-3') ## todo: dynamically find last checkpoint\n",
    "ckpt.restore(model_checkpoint).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
